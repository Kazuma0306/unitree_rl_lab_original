import h5py
import matplotlib.pyplot as plt

# path = "teacher_static.h5"  # â†ã‚ãªãŸã®ãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã¦
# with h5py.File(path, "r") as f:
#     print("keys:", list(f.keys()))
#     rgb = f["rgb"]  # (N,H,W,3) uint8

#     print("rgb shape:", rgb.shape, "dtype:", rgb.dtype)

#     # ä¾‹ï¼šå…ˆé ­5æšã‚’è¡¨ç¤º
#     for i in range(5):
#         img = rgb[i]  # HWC
#         plt.figure()
#         plt.title(f"rgb[{i}]")
#         plt.imshow(img)
#         plt.axis("off")
#     plt.show()




import h5py
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# ---------------------------
# ã“ã“ã ã‘ã‚ãªãŸã®è¨­å®šã«åˆã‚ã›ã‚‹
# ---------------------------
# PATH = "/home/digital/isaac_ws/unitree_rl_lab/teacher_static.h5"
PATH = "/home/digital/isaac_ws/unitree_rl_lab/teacher_walk.h5"

# BEVï¼ˆraycasterã¨åˆã‚ã›ã‚‹ï¼‰
L = 1.2
W = 0.6
Z_PLANE = 0.0   # worldã®åœ°é¢é«˜ã•ï¼ˆã‚ãªãŸã®å‰æï¼‰

# ã‚«ãƒ¡ãƒ© intrinsicsï¼ˆIsaacã® PinholeCameraCfg ã‹ã‚‰è¿‘ä¼¼ï¼‰
IMG_H = 64
IMG_W = 64
FOCAL_LEN = 10.5          # focal_length
H_APERTURE = 20.955       # horizontal_aperture
# vertical_aperture ã¯æœªæŒ‡å®šãªã‚‰æ¨ªã¨ã‚¢ã‚¹ãƒšã‚¯ãƒˆã§æ±ºã¾ã‚‹æƒ³å®šï¼ˆæ­£æ–¹å½¢ãªã‚‰åŒã˜ï¼‰
V_APERTURE = H_APERTURE * (IMG_H / IMG_W)

# è¿‘ä¼¼ pinhole: fx = Wpx * f / sensor_width, fy = Hpx * f / sensor_height
fx = IMG_W * FOCAL_LEN / H_APERTURE
fy = IMG_H * FOCAL_LEN / V_APERTURE
cx = (IMG_W - 1) * 0.5
cy = (IMG_H - 1) * 0.5

# ã‚«ãƒ¡ãƒ© offsetï¼ˆbase -> camï¼‰
# OffsetCfg.pos / rot ã‚’ãã®ã¾ã¾å…¥ã‚Œã‚‹ï¼ˆrotã¯ wxyzï¼‰
t_bc = torch.tensor([0.370, 0.0, 0.15], dtype=torch.float32)
# q_bc_wxyz = torch.tensor([0.5, -0.5, 0.5, -0.5], dtype=torch.float32)
# q_bc_wxyz = torch.tensor([0.2418, -0.6645,  0.6645, -0.2418], dtype=torch.float32)



# ---------------------------
# å›è»¢ãƒ»å§¿å‹¢ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ---------------------------
def quat_to_rotmat_wxyz(q):
    """q: (...,4) in (w,x,y,z) -> R: (...,3,3)"""
    w, x, y, z = q.unbind(-1)
    ww, xx, yy, zz = w*w, x*x, y*y, z*z
    wx, wy, wz = w*x, w*y, w*z
    xy, xz, yz = x*y, x*z, y*z

    R = torch.stack([
        ww+xx-yy-zz, 2*(xy-wz),     2*(xz+wy),
        2*(xy+wz),   ww-xx+yy-zz,   2*(yz-wx),
        2*(xz-wy),   2*(yz+wx),     ww-xx-yy+zz
    ], dim=-1).reshape(q.shape[:-1] + (3,3))
    return R

def yaw_from_quat_wxyz(q):
    """world Z-yaw from quaternion wxyz"""
    w,x,y,z = q.unbind(-1)
    siny = 2*(w*z + x*y)
    cosy = 1 - 2*(y*y + z*z)
    return torch.atan2(siny, cosy)

def rotz(yaw):
    c = torch.cos(yaw); s = torch.sin(yaw)
    R = torch.zeros(yaw.shape + (3,3), dtype=yaw.dtype, device=yaw.device)
    R[...,0,0]=c; R[...,0,1]=-s
    R[...,1,0]=s; R[...,1,1]=c
    R[...,2,2]=1
    return R

@torch.no_grad()
def rgb_to_bev_ipm(rgb_bchw, base_pos_w, base_quat_wxyz, Hb, Wb):
    """
    rgb_bchw: (1,3,H,W) float [0,1]
    base_pos_w: (3,)
    base_quat_wxyz: (4,)
    Hb,Wb: BEV grid size
    returns: bev (1,3,Hb,Wb)
    """

    dev = rgb_bchw.device
    dtype = rgb_bchw.dtype

    # BEVã‚»ãƒ«ä¸­å¿ƒ (x_b,y_b) ã‚’ä½œã‚‹ï¼ˆraycasterã¨åŒã˜ç¯„å›²ï¼‰
    xs = torch.linspace(-L/2, L/2, Hb, device=dev, dtype=dtype)
    ys = torch.linspace(-W/2, W/2, Wb, device=dev, dtype=dtype)
    xg, yg = torch.meshgrid(xs, ys, indexing="ij")  # (Hb,Wb)
    pw = torch.stack([xg, yg, torch.zeros_like(xg)], dim=-1)  # (Hb,Wb,3)

    # worldä¸Šã®å¹³é¢ç‚¹ï¼ˆyawã®ã¿ã§å›ã™ï¼šattach_yaw_onlyç›¸å½“ï¼‰
    yaw = yaw_from_quat_wxyz(base_quat_wxyz[None])[0]
    R_yaw = rotz(yaw)  # (3,3)

    p0 = base_pos_w.clone()
    p0[2] = Z_PLANE
    Xw = (R_yaw[None,None,:,:] @ pw[...,None]).squeeze(-1) + p0[None,None,:]  # (Hb,Wb,3)

    # ã‚«ãƒ¡ãƒ©ã® world pose ã‚’åˆæˆï¼ˆãƒ•ãƒ«å§¿å‹¢ã§ï¼‰
    R_wb = quat_to_rotmat_wxyz(base_quat_wxyz[None])[0]  # (3,3)
    R_bc = quat_to_rotmat_wxyz(q_bc_wxyz[None].to(dev))[0].to(dtype)         # (3,3)
    t_bc_ = t_bc.to(dev, dtype)

    R_wc = R_wb @ R_bc
    t_wc = base_pos_w + (R_wb @ t_bc_)  # worldä½ç½®

    # world -> cam
    R_cw = R_wc.T
    t_cw = -(R_cw @ t_wc)

    Xc = (R_cw[None,None,:,:] @ Xw[...,None]).squeeze(-1) + t_cw[None,None,:]  # (Hb,Wb,3)

    Z = Xc[...,2].clamp(min=1e-6)   # ROS optical: +Z forward ã¨ã—ã¦æŠ•å½±
    u = fx * (Xc[...,0] / Z) + cx
    v = fy * (Xc[...,1] / Z) + cy

    Himg, Wimg = rgb_bchw.shape[-2], rgb_bchw.shape[-1]
    grid_x = 2.0 * (u / (Wimg - 1.0)) - 1.0
    grid_y = 2.0 * (v / (Himg - 1.0)) - 1.0
    grid = torch.stack([grid_x, grid_y], dim=-1)[None, ...]  # (1,Hb,Wb,2)

    bev = F.grid_sample(rgb_bchw, grid, mode="bilinear",
                        padding_mode="zeros", align_corners=True)
    return bev




# with h5py.File(PATH, "r") as f:
#     def show(name, obj):
#         if isinstance(obj, h5py.Dataset):
#             print(name, obj.shape, obj.dtype)
#     f.visititems(show)



# # ---------------------------
# # å¯è¦–åŒ–
# # ---------------------------
# with h5py.File(PATH, "r") as f:
#     print("keys:", list(f.keys()))
#     rgb = f["rgb"]            # (N,H,W,3) æƒ³å®š
#     root = f["root_state_w"]          # (N,13) æƒ³å®š
#     hits_z = f["hits_z"]      # (N,Hb,Wb) ãŒã‚ã‚‹ãªã‚‰ BEVã‚µã‚¤ã‚ºã«ä½¿ã†

#     N = rgb.shape[0]
#     Hb, Wb = hits_z.shape[1], hits_z.shape[2]

#     for i in range(min(5, N)):
#         img = rgb[i]  # HWC uint8
#         # torchã¸
#         img_t = torch.from_numpy(img).float() / 255.0  # (H,W,3)
#         img_t = img_t.permute(2,0,1).unsqueeze(0)      # (1,3,H,W)

#         r = np.array(root[i], dtype=np.float32)
#         base_pos_w = torch.from_numpy(r[0:3])
#         base_quat_wxyz = torch.from_numpy(r[3:7])  # IsaacLab root_state_w ã¯é€šå¸¸ wxyz

#         bev = rgb_to_bev_ipm(img_t, base_pos_w, base_quat_wxyz, Hb, Wb)  # (1,3,Hb,Wb)
#         bev_np = bev[0].permute(1,2,0).clamp(0,1).cpu().numpy()

#         plt.figure(figsize=(8,4))
#         plt.subplot(1,2,1)
#         plt.title(f"rgb[{i}]")
#         plt.imshow(img)
#         plt.axis("off")

#         plt.subplot(1,2,2)
#         plt.title(f"BEV z={Z_PLANE}  HbxWb={Hb}x{Wb}")
#         plt.imshow(bev_np)
#         plt.axis("off")

#         plt.tight_layout()

#     plt.show()





import h5py, numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# ---- å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚ãªãŸã®è¨­å®šï¼‰----
# PATH = "teacher_static.h5"
L, W = 1.2, 0.6
Z_PLANE = 0.0

IMG_H = 64; IMG_W = 64
FOCAL_LEN = 10.5
H_APERTURE = 20.955
V_APERTURE = H_APERTURE * (IMG_H / IMG_W)

fx = IMG_W * FOCAL_LEN / H_APERTURE
fy = IMG_H * FOCAL_LEN / V_APERTURE
cx = (IMG_W - 1) * 0.5
cy = (IMG_H - 1) * 0.5

t_off = torch.tensor([0.370, 0.0, 0.15], dtype=torch.float32)
q_off_wxyz = torch.tensor([0.4056, -0.5792, 0.4056, -0.5792], dtype=torch.float32)

def quat_to_R_wxyz(q):
    w,x,y,z = q.unbind(-1)
    ww,xx,yy,zz = w*w,x*x,y*y,z*z
    wx,wy,wz = w*x,w*y,w*z
    xy,xz,yz = x*y,x*z,y*z
    R = torch.stack([
        ww+xx-yy-zz, 2*(xy-wz),     2*(xz+wy),
        2*(xy+wz),   ww-xx+yy-zz,   2*(yz-wx),
        2*(xz-wy),   2*(yz+wx),     ww-xx-yy+zz
    ], dim=-1).reshape(q.shape[:-1]+(3,3))
    return R

def quat_to_R_xyzw(q):
    x,y,z,w = q.unbind(-1)
    return quat_to_R_wxyz(torch.stack([w,x,y,z], dim=-1))

def yaw_from_quat_wxyz(q):
    w,x,y,z = q.unbind(-1)
    siny = 2*(w*z + x*y)
    cosy = 1 - 2*(y*y + z*z)
    return torch.atan2(siny, cosy)

def rotz(yaw):
    c = torch.cos(yaw); s = torch.sin(yaw)
    R = torch.zeros(yaw.shape+(3,3), dtype=yaw.dtype, device=yaw.device)
    R[...,0,0]=c; R[...,0,1]=-s
    R[...,1,0]=s; R[...,1,1]=c
    R[...,2,2]=1
    return R

def make_bev_world_points(base_pos_w, base_quat_wxyz, Hb, Wb):
    # BEV grid in base-yaw frame
    xs = torch.linspace(-L/2, L/2, Hb, dtype=torch.float32)
    ys = torch.linspace(-W/2, W/2, Wb, dtype=torch.float32)
    xg, yg = torch.meshgrid(xs, ys, indexing="ij")
    pw = torch.stack([xg, yg, torch.zeros_like(xg)], dim=-1)  # (Hb,Wb,3)

    yaw = yaw_from_quat_wxyz(base_quat_wxyz[None])[0]
    R_y = rotz(yaw)
    p0 = base_pos_w.clone()
    p0[2] = Z_PLANE
    Xw = (R_y[None,None,:,:] @ pw[...,None]).squeeze(-1) + p0[None,None,:]
    return Xw  # (Hb,Wb,3)

def compose_Twc(base_pos_w, base_R_wb, off_R, off_t, off_is_cam_to_base: bool):
    # off: either cam->base or base->cam
    if off_is_cam_to_base:
        R_wc = base_R_wb @ off_R
        t_wc = base_pos_w + (base_R_wb @ off_t)
    else:
        # invert base->cam to cam->base
        R_cb = off_R
        t_cb = off_t
        R_bc = R_cb.transpose(-1,-2)
        t_bc = -(R_bc @ t_cb)
        R_wc = base_R_wb @ R_bc
        t_wc = base_pos_w + (base_R_wb @ t_bc)
    return R_wc, t_wc  # cam->world

def project_uv(Xc, depth_axis: str):
    # depth_axis: "Z" (optical) or "X" (ros-forward)
    if depth_axis == "Z":
        Z = Xc[...,2].clamp(min=1e-6)
        u = fx*(Xc[...,0]/Z) + cx
        v = fy*(Xc[...,1]/Z) + cy
        depth = Xc[...,2]
    else:  # "X"
        Z = Xc[...,0].clamp(min=1e-6)
        u = fx*(Xc[...,1]/Z) + cx
        v = fy*(Xc[...,2]/Z) + cy
        depth = Xc[...,0]
    return u, v, depth

@torch.no_grad()
def try_one(img_bchw, root13, Hb, Wb, quat_order, off_is_cam_to_base, depth_axis):
    # root
    base_pos_w = torch.from_numpy(root13[0:3]).float()
    q = torch.from_numpy(root13[3:7]).float()
    if quat_order == "wxyz":
        base_R = quat_to_R_wxyz(q[None])[0]
        base_q_wxyz = q
    else:
        base_R = quat_to_R_xyzw(q[None])[0]
        # yawç”¨ã«wxyzã¸
        base_q_wxyz = torch.stack([q[3],q[0],q[1],q[2]])

    # off
    off_R = quat_to_R_wxyz(q_off_wxyz[None])[0]
    off_t = t_off

    # points on world plane
    Xw = make_bev_world_points(base_pos_w, base_q_wxyz, Hb, Wb)  # (Hb,Wb,3)

    # cam pose
    R_wc, t_wc = compose_Twc(base_pos_w, base_R, off_R, off_t, off_is_cam_to_base)
    R_cw = R_wc.transpose(-1,-2)
    t_cw = -(R_cw @ t_wc)


    # Camera offset (wxyz) base->cam ï¼ˆåè»¢ã—ãªã„ï¼‰
    # t_bc = torch.tensor([0.370, 0.0, 0.15], dtype=torch.float32)
    # q_bc_wxyz = torch.tensor([0.4056, -0.5792, 0.4056, -0.5792], dtype=torch.float32)

    # # 1) base worldå›è»¢ã¯ã€Œã‚«ãƒ¡ãƒ©å§¿å‹¢ã€ã«ã¯ãƒ•ãƒ«å›è»¢ã‚’ä½¿ã†ï¼ˆãƒ­ãƒ¼ãƒ«/ãƒ”ãƒƒãƒå«ã‚€ï¼‰
    # R_wb = quat_to_R_wxyz(base_q_wxyz[None])[0]
    # R_bc = quat_to_R_wxyz(q_bc_wxyz[None])[0]
    # R_wc = R_wb @ R_bc
    # t_wc = base_pos_w.float() + (R_wb @ t_bc)

    # # world->cam
    # R_cw = R_wc.T
    # t_cw = -(R_cw @ t_wc)

    # Xw = make_bev_world_points(base_pos_w, base_q_wxyz, Hb, Wb)  # (Hb,Wb,3)


    # world->cam
    Xc = (R_cw[None,None,:,:] @ Xw[...,None]).squeeze(-1) + t_cw[None,None,:]

    u, v, depth = project_uv(Xc, depth_axis)
    inb = (u >= 0) & (u <= IMG_W-1) & (v >= 0) & (v <= IMG_H-1) & (depth > 0.05)
    ratio = inb.float().mean().item()

    # sample
    grid_x = 2.0*(u/(IMG_W-1.0)) - 1.0
    grid_y = 2.0*(v/(IMG_H-1.0)) - 1.0
    grid = torch.stack([grid_x, grid_y], dim=-1)[None]  # (1,Hb,Wb,2)

    bev = F.grid_sample(img_bchw, grid, mode="bilinear", padding_mode="zeros", align_corners=True)
    return ratio, bev

# with h5py.File(PATH, "r") as f:
#     rgb = f["rgb"]
#     root = f["root_state_w"]
#     Hb, Wb = f["hits_z"].shape[1], f["hits_z"].shape[2]

#     i = 0
#     img = rgb[i]  # HWC uint8
#     img_t = torch.from_numpy(img).float()/255.0
#     img_t = img_t.permute(2,0,1).unsqueeze(0)  # (1,3,H,W)
#     r = np.array(root[i], dtype=np.float32)

#     best = None
#     for quat_order in ["wxyz"]:
#         for off_is_cam_to_base in [False]:
#             for depth_axis in ["Z"]:
#                 ratio, bev = try_one(img_t, r, Hb, Wb, quat_order, off_is_cam_to_base, depth_axis)
#                 cfg = (quat_order, off_is_cam_to_base, depth_axis)
#                 if (best is None) or (ratio > best[0]):
#                     best = (ratio, cfg, bev)

#     ratio, cfg, bev = best
#     print("best in-bounds ratio:", ratio, "cfg:", cfg)

#     bev_np = bev[0].permute(1,0,2).clamp(0,1).numpy()
#     # bev_show = bev.permute(1, 0, 2)  # (Wb,Hb,3)
#     # bev0 = bev[0]                       # (3,Hb,Wb)
#     # bev_rgb = bev0.permute(1,2,0)       # (Hb,Wb,3)  <- imshowå‘ã‘
#     # bev_show = bev_rgb.permute(1,0,2)   # (Wb,Hb,3)  <- æ¨ª=xã«ã—ãŸã„è¡¨ç¤º

#     bev0 = bev[0].permute(1, 2, 0)      # (Hb,Wb,3)  i=x, j=y
#     bev_show = torch.flip(bev0, dims=[0, 1])  # â˜…xã‚‚yã‚‚åè»¢

#     x_min, x_max = -L/2, L/2


#     plt.imshow(bev_show.clamp(0,1).cpu().numpy(),
#             origin="upper",
#             extent=[W/2, -W/2, x_min, x_max],   # æ¨ªè»¸= y, ç¸¦è»¸= x
#             aspect="equal")
#     plt.xlabel("y left [m]")
#     plt.ylabel("x forward [m]")
#     plt.title("Top-down BEV (top=+x, left=+y)")
#     plt.show()




#     plt.figure(figsize=(8,4))
#     plt.subplot(1,2,1); plt.title("RGB"); plt.imshow(img); plt.axis("off")
#     # plt.imshow(bev_show, origin="lower", extent=[0, L, W/2, -W/2], aspect="auto")

#     # plt.subplot(1,2,2); plt.title(f"BEV ratio={ratio:.3f}\n{cfg}"); plt.imshow(bev_np); plt.axis("off")
#     plt.tight_layout()
#     plt.show()



# import h5py
# import numpy as np
# import torch
# import torch.nn.functional as F
# import matplotlib.pyplot as plt

# # ---- å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ----
# PATH = "teacher_static.h5"
# L, W = 1.2, 0.6
# Z_PLANE = 0.0

# IMG_H = 64; IMG_W = 64
# FOCAL_LEN = 10.5
# H_APERTURE = 20.955
# V_APERTURE = H_APERTURE * (IMG_H / IMG_W)

# fx = IMG_W * FOCAL_LEN / H_APERTURE
# fy = IMG_H * FOCAL_LEN / V_APERTURE
# cx = (IMG_W - 1) * 0.5
# cy = (IMG_H - 1) * 0.5

# # ãƒ™ãƒ¼ã‚¹(ãƒ­ãƒœãƒƒãƒˆä¸­å¿ƒ)ã‹ã‚‰è¦‹ãŸã‚«ãƒ¡ãƒ©ã®ä½ç½®ã¨å§¿å‹¢ (T_bc)
# # ã“ã‚Œã‚‰ã¯é€šå¸¸ "Base to Camera" ã®å¤‰æ›ã¨ã—ã¦å®šç¾©ã•ã‚Œã¾ã™
# t_off = torch.tensor([0.370, 0.0, 0.15], dtype=torch.float32) # Baseå‰æ–¹37cm, é«˜ã•15cm
# q_off_wxyz = torch.tensor([0.4056, -0.5792, 0.4056, -0.5792], dtype=torch.float32)

# def quat_to_R_wxyz(q):
#     w,x,y,z = q.unbind(-1)
#     ww,xx,yy,zz = w*w,x*x,y*y,z*z
#     wx,wy,wz = w*x,w*y,w*z
#     xy,xz,yz = x*y,x*z,y*z
#     R = torch.stack([
#         ww+xx-yy-zz, 2*(xy-wz),     2*(xz+wy),
#         2*(xy+wz),   ww-xx+yy-zz,   2*(yz-wx),
#         2*(xz-wy),   2*(yz+wx),     ww-xx-yy+zz
#     ], dim=-1).reshape(q.shape[:-1]+(3,3))
#     return R

# def make_bev_world_points(base_pos_w, base_quat_wxyz, Hb, Wb):
#     """
#     BEVç”»åƒã®å„ãƒ”ã‚¯ã‚»ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒ¯ãƒ¼ãƒ«ãƒ‰åº§æ¨™ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
#     """
#     # ã€ä¿®æ­£ç‚¹1ã€‘
#     # ç”»åƒã®è¡Œ(0è¡Œç›®)ã‚’ã€Œå‰æ–¹(+L/2)ã€ã«ã€æœ€çµ‚è¡Œã‚’ã€Œå¾Œæ–¹(-L/2)ã€ã«å¯¾å¿œã•ã›ã‚‹
#     # ã“ã‚Œã«ã‚ˆã‚Šç”»åƒã®ä¸Šå´ãŒãƒ­ãƒœãƒƒãƒˆã®å‰æ–¹ã«ãªã‚Šã¾ã™
#     xs = torch.linspace(L/2, -L/2, Hb, dtype=torch.float32) 
    
#     # ç”»åƒã®åˆ—(0åˆ—ç›®)ã¯ã€Œå·¦(-W/2)ã€ã€æœ€çµ‚åˆ—ã¯ã€Œå³(W/2)ã€
#     ys = torch.linspace(-W/2, W/2, Wb, dtype=torch.float32)
    
#     xg, yg = torch.meshgrid(xs, ys, indexing="ij")
    
#     # ãƒ™ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã®ã‚°ãƒªãƒƒãƒ‰åº§æ¨™ (Hb, Wb, 3)
#     p_base = torch.stack([xg, yg, torch.zeros_like(xg)], dim=-1)

#     # Base -> World å¤‰æ›
#     # 1. Baseã®å›è»¢è¡Œåˆ—ã‚’å–å¾— (Yawã®ã¿è€ƒæ…®ã™ã‚‹å ´åˆã¨ã€å…¨å§¿å‹¢è€ƒæ…®ã™ã‚‹å ´åˆãŒã‚ã‚‹ãŒã€BEVå¹³é¢å›ºå®šãªã‚‰Yawã®ã¿ã§è‰¯ã„ã“ã¨ãŒå¤šã„)
#     # ã“ã“ã§ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ã®æ„å›³ã‚’æ±²ã¿ã€Yawå›è»¢ã ã‘é©ç”¨ã—ã¦Zå¹³é¢ã«è²¼ã‚Šä»˜ã‘ã¾ã™
#     base_R = quat_to_R_wxyz(base_quat_wxyz)
    
#     # ã‚·ãƒ³ãƒ—ãƒ«ã« World = R_wb @ p_base + t_wb ã§è¨ˆç®—
#     # â€»å…ƒã‚³ãƒ¼ãƒ‰ã®yawè¨ˆç®—ã¨rotzã¯æ­£ã—ã„ã§ã™ãŒã€è¡Œåˆ—æ¼”ç®—ã§ä¸€æ‹¬å‡¦ç†ã—ã¾ã™
#     Xw = (base_R[None, None, :, :] @ p_base[..., None]).squeeze(-1) + base_pos_w[None, None, :]
    
#     # Zåº§æ¨™ã‚’å¼·åˆ¶çš„ã«å›ºå®šå¹³é¢ã«ã™ã‚‹å ´åˆï¼ˆåœ°é¢æŠ•å½±ï¼‰
#     Xw[..., 2] = Z_PLANE
    
#     return Xw

# def get_cam_pose_cw(base_pos_w, base_quat_wxyz):
#     """
#     World -> Camera ã®å¤‰æ›è¡Œåˆ— (R_cw, t_cw) ã‚’è¨ˆç®—
#     """
#     # 1. T_wb (World -> Base)
#     R_wb = quat_to_R_wxyz(base_quat_wxyz)
#     t_wb = base_pos_w

#     # 2. T_bc (Base -> Camera) å›ºå®šã‚ªãƒ•ã‚»ãƒƒãƒˆ
#     R_bc = quat_to_R_wxyz(q_off_wxyz)
#     t_bc = t_off

#     # 3. T_wc (World -> Camera) = T_wb * T_bc
#     # R_wc = R_wb @ R_bc
#     # t_wc = R_wb @ t_bc + t_wb
#     R_wc = R_wb @ R_bc
#     t_wc = (R_wb @ t_bc) + t_wb

#     # 4. T_cw (Camera -> World) = inv(T_wc)
#     # ç›´äº¤è¡Œåˆ—ã®é€†è¡Œåˆ—ã¯è»¢ç½®
#     R_cw = R_wc.t()
#     t_cw = -(R_cw @ t_wc)
    
#     return R_cw, t_cw

# def project_uv(Xc):
#     """
#     ã‚«ãƒ¡ãƒ©åº§æ¨™ç³» (Z-forward) ã®ç‚¹ã‚’ç”»åƒå¹³é¢ (u, v) ã«æŠ•å½±
#     """
#     # å…¸å‹çš„ãªã‚«ãƒ¡ãƒ©åº§æ¨™ç³»: X=Right, Y=Down, Z=Forward
#     # æ·±åº¦ã¯ Z è»¸
#     eps = 1e-6
#     Z = Xc[..., 2].clamp(min=eps)
#     X = Xc[..., 0]
#     Y = Xc[..., 1]
    
#     u = fx * (X / Z) + cx
#     v = fy * (Y / Z) + cy
#     return u, v, Z

# @torch.no_grad()
# def generate_bev(img_tensor, root_state, Hb, Wb):
#     # root_state ã‹ã‚‰ä½ç½®ã¨å§¿å‹¢ã‚’æŠ½å‡º
#     base_pos_w = torch.from_numpy(root_state[0:3]).float()
#     # wxyzã«ä¸¦ã¹æ›¿ãˆ (h5ã®ä¸¦ã³é †ãŒ[pos, quat(wxyz)]ã§ã‚ã‚‹ã¨ä»®å®š)
#     # ã‚‚ã—h5ãŒxyzwãªã‚‰ä¿®æ­£ãŒå¿…è¦ã§ã™ãŒã€å…ƒã‚³ãƒ¼ãƒ‰ã«å¾“ã„wxyzã¨ã—ã¦æ‰±ã„ã¾ã™
#     base_q_wxyz = torch.from_numpy(root_state[3:7]).float() 

#     # 1. BEVã‚°ãƒªãƒƒãƒ‰ã®Worldåº§æ¨™è¨ˆç®—
#     Xw = make_bev_world_points(base_pos_w, base_q_wxyz, Hb, Wb) # (Hb, Wb, 3)

#     # 2. World -> Camera å¤‰æ›è¡Œåˆ—ã®è¨ˆç®—
#     R_cw, t_cw = get_cam_pose_cw(base_pos_w, base_q_wxyz)

#     # 3. Worldåº§æ¨™ã‚’Cameraåº§æ¨™ã¸å¤‰æ›
#     # Xc = R_cw * Xw + t_cw
#     Xc = (R_cw[None, None, :, :] @ Xw[..., None]).squeeze(-1) + t_cw[None, None, :]

#     # 4. UVæŠ•å½±
#     u, v, depth = project_uv(Xc)

#     # 5. grid_sample ç”¨ã«æ­£è¦åŒ– (-1 ~ 1)
#     # grid_x å¯¾å¿œ u (å¹…æ–¹å‘), grid_y å¯¾å¿œ v (é«˜ã•æ–¹å‘)
#     grid_x = 2.0 * (u / (IMG_W - 1.0)) - 1.0
#     grid_y = 2.0 * (v / (IMG_H - 1.0)) - 1.0
    
#     # ã‚«ãƒ¡ãƒ©ã®è£å´(depth<=0)ã‚„ç”»è§’å¤–ã‚’ãƒã‚¹ã‚¯ã™ã‚‹ãŸã‚ã®æº–å‚™
#     mask = (u >= 0) & (u <= IMG_W-1) & (v >= 0) & (v <= IMG_H-1) & (depth > 0.1)
    
#     # ã‚°ãƒªãƒƒãƒ‰ç”Ÿæˆ (N, H, W, 2)
#     grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0)
    
#     # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
#     # border_paddingã ã¨ç”»è§’å¤–ãŒå¼•ãä¼¸ã°ã•ã‚Œã‚‹ã®ã§ zeros ãŒç„¡é›£
#     bev = F.grid_sample(img_tensor, grid, mode="bilinear", padding_mode="zeros", align_corners=True)
    
#     return bev, mask

# # ---- ãƒ¡ã‚¤ãƒ³å‡¦ç† ----
# with h5py.File(PATH, "r") as f:
#     rgb = f["rgb"]
#     root = f["root_state_w"]
#     Hb, Wb = f["hits_z"].shape[1], f["hits_z"].shape[2]

#     i = 0  # ä»»æ„ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
#     img_np = rgb[i]
#     img_t = torch.from_numpy(img_np).float() / 255.0
#     img_t = img_t.permute(2, 0, 1).unsqueeze(0) # (1, 3, H, W)
#     r = np.array(root[i], dtype=np.float32)

#     bev, mask = generate_bev(img_t, r, Hb, Wb)
    
#     # è¡¨ç¤º
#     bev_np = bev[0].permute(1, 2, 0).clamp(0, 1).numpy()
#     mask_np = mask.float().numpy()

#     plt.figure(figsize=(10, 5))
    
#     plt.subplot(1, 3, 1)
#     plt.title("Front Camera Input")
#     plt.imshow(img_np)
#     plt.axis("off")

#     plt.subplot(1, 3, 2)
#     plt.title("BEV Output")
#     plt.imshow(bev_np)
#     # ãƒ­ãƒœãƒƒãƒˆä½ç½®ã®å›³ç¤ºï¼ˆç”»åƒã®ä¸‹ä¸­å¤®ï¼‰
#     plt.plot(Wb/2, Hb, 'r^', markersize=10, label="Robot") 
#     plt.legend(loc='lower center')
#     plt.axis("off")
    
#     plt.subplot(1, 3, 3)
#     plt.title("Valid Projection Mask")
#     plt.imshow(mask_np, cmap="gray")
#     plt.axis("off")

#     plt.tight_layout()
#     plt.show()


import h5py
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# ---- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š ----
# PATH = "teacher_static.h5"

# ã€é‡è¦ã€‘BEVã®è¡¨ç¤ºç¯„å›²è¨­å®š
# ãƒ­ãƒœãƒƒãƒˆåº§æ¨™ç³» (Base Link) ã§ã®ç¯„å›²ã‚’æŒ‡å®šã—ã¾ã™
# ã‚«ãƒ¡ãƒ©ãŒ x=0.37, z=0.15 ã«ã‚ã‚‹ãŸã‚ã€æ­»è§’ã‚’é¿ã‘ã¦ x=0.5 ã‚ãŸã‚Šã‹ã‚‰æç”»ã—ã¾ã™
X_MIN = 0.4   # æ‰‹å‰ (m)
X_MAX = 1.2  # å¥¥ (m)
Y_WIDTH = 0.8 # æ¨ªå¹… (m) -> Y: +1.5 ~ -1.5

BEV_H = 128# å‡ºåŠ›ç”»åƒã®é«˜ã•
BEV_W = 64  # å‡ºåŠ›ç”»åƒã®å¹…
Z_GROUND = -0.30

# ã‚«ãƒ¡ãƒ©å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
IMG_H = 64; IMG_W = 64
FOCAL_LEN = 10.5
H_APERTURE = 20.955
V_APERTURE = H_APERTURE * (IMG_H / IMG_W)
fx = IMG_W * FOCAL_LEN / H_APERTURE
fy = IMG_H * FOCAL_LEN / V_APERTURE
cx = (IMG_W - 1) * 0.5
cy = (IMG_H - 1) * 0.5

# ãƒ™ãƒ¼ã‚¹(Robot) -> ã‚«ãƒ¡ãƒ©(Camera) ã®å¤‰æ›
# t_off: Baseã‹ã‚‰è¦‹ãŸCameraã®ä½ç½®
t_bc = torch.tensor([0.370, 0.0, 0.15], dtype=torch.float32)
# q_off: Baseåº§æ¨™ç³»ã‚’Cameraåº§æ¨™ç³»ã«åˆã‚ã›ã‚‹å›è»¢ (ã‚ã‚‹ã„ã¯ãã®é€†)
# é€šå¸¸ã€TFãƒ‡ãƒ¼ã‚¿ã¯ "Parent to Child" (Base -> Camera) ã®å›è»¢ã‚’è¡¨ã—ã¾ã™
# q_bc_wxyz = torch.tensor([0.5, -0.5, 0.5, -0.5], dtype=torch.float32)
q_bc_wxyz = torch.tensor([0.2418, -0.6645,  0.6645, -0.2418], dtype=torch.float32)


def quat_to_R_wxyz(q):
    w,x,y,z = q.unbind(-1)
    ww,xx,yy,zz = w*w,x*x,y*y,z*z
    wx,wy,wz = w*x,w*y,w*z
    xy,xz,yz = x*y,x*z,y*z
    R = torch.stack([
        ww+xx-yy-zz, 2*(xy-wz),     2*(xz+wy),
        2*(xy+wz),   ww-xx+yy-zz,   2*(yz-wx),
        2*(xz-wy),   2*(yz+wx),     ww-xx-yy+zz
    ], dim=-1).reshape(q.shape[:-1]+(3,3))
    return R

def make_bev_grid_points(Hb, Wb):
    """
    BEVç”»åƒã®å„ãƒ”ã‚¯ã‚»ãƒ«ã«å¯¾å¿œã™ã‚‹ã€Œãƒ­ãƒœãƒƒãƒˆåº§æ¨™ç³»(Base)ã€ã§ã®ä½ç½®(x,y,0)ã‚’ä½œæˆ
    ç”»åƒä¸Š(row=0) = X_MAX (é ã)
    ç”»åƒä¸‹(row=H) = X_MIN (æ‰‹å‰)
    ç”»åƒå·¦(col=0) = Y_MAX (+Y, å·¦)
    ç”»åƒå³(col=W) = Y_MIN (-Y, å³)
    """
    xs = torch.linspace(X_MAX, X_MIN, Hb, dtype=torch.float32)
    ys = torch.linspace(Y_WIDTH/2, -Y_WIDTH/2, Wb, dtype=torch.float32)
    
    xg, yg = torch.meshgrid(xs, ys, indexing="ij")
    zg = torch.full_like(xg, Z_GROUND)
    
    # (Hb, Wb, 3) -> Baseåº§æ¨™ç³»ã§ã®ç‚¹ç¾¤
    points_base = torch.stack([xg, yg, zg], dim=-1)
    return points_base

def transform_points_base_to_cam(points_base, R_bc, t_bc):
    """
    ç‚¹ç¾¤ã‚’ Baseåº§æ¨™ç³» -> Cameraåº§æ¨™ç³» ã¸å¤‰æ›
    P_cam = R_bc^T * (P_base - t_bc)
    """
    # 1. ä¸¦é€²ã‚’å¼•ã
    p_centered = points_base - t_bc
    
    # 2. å›è»¢ï¼ˆR_bc ã®é€†è¡Œåˆ—ï¼è»¢ç½®è¡Œåˆ—ã‚’æ›ã‘ã‚‹ï¼‰
    # è¡Œåˆ—ç©: (N, 3) @ (3, 3) ã®å½¢ã«ã™ã‚‹ãŸã‚å·¥å¤«
    # R_bc.t() @ vector
    
    R_cb = R_bc.t() # Base->Cam ã®é€†ã¯ Cam->Base ã§ã¯ãªãã€é€†å›è»¢
    
    # einsumã§ (Hb, Wb, 3) x (3, 3) -> (Hb, Wb, 3)
    # p_centered[... , j] * R_cb[j, i] -> out[... , i]
    points_cam = torch.einsum('...j,ij->...i', p_centered, R_cb)

    
    return points_cam

def project_to_uv(points_cam):
    """
    Cameraåº§æ¨™ç³»ã®ç‚¹ã‚’ç”»åƒå¹³é¢ã¸æŠ•å½±
    Cameraåº§æ¨™ç³»å®šç¾©: Z=Forward(Depth), X=Right, Y=Down (OpenCV/Standard)
    """
    eps = 1e-6
    X = points_cam[..., 0]
    Y = points_cam[..., 1]
    Z = points_cam[..., 2]
    
    # ã‚«ãƒ¡ãƒ©ã®å¾Œã‚ã«ã‚ã‚‹ç‚¹ã¯ç„¡åŠ¹
    valid_mask = Z > 0.1
    
    u = fx * (X / Z.clamp(min=eps)) + cx
    v = fy * (Y / Z.clamp(min=eps)) + cy
    
    return u, v, Z, valid_mask

@torch.no_grad()
def generate_bev(img_t, Hb, Wb):
    # 1. BEVã‚°ãƒªãƒƒãƒ‰ï¼ˆãƒ­ãƒœãƒƒãƒˆåº§æ¨™ç³»ï¼‰ä½œæˆ
    points_base = make_bev_grid_points(Hb, Wb)
    
    # 2. Base -> Camera å¤‰æ›
    # ä»Šå›ã¯Robotã®ç§»å‹•(Worldåº§æ¨™)ã¯ç„¡è¦–ã—ã€Robotåº§æ¨™ç³»ã ã‘ã§è€ƒãˆã‚Œã°OKã§ã™
    # ï¼ˆã‚«ãƒ¡ãƒ©ç”»åƒã¯Robotã«ã¤ã„ã¦ã„ã‚‹ã‚«ãƒ¡ãƒ©ã‹ã‚‰è¦‹ãŸã‚‚ã®ãªã®ã§ï¼‰
    R_bc = quat_to_R_wxyz(q_bc_wxyz)
    points_cam = transform_points_base_to_cam(points_base, R_bc, t_bc)
    
    # 3. æŠ•å½± (UVè¨ˆç®—)
    u, v, depth, valid_mask = project_to_uv(points_cam)
    
    # ãƒ‡ãƒãƒƒã‚°: æŠ•å½±ã•ã‚ŒãŸUVã®ä¸­å¿ƒä»˜è¿‘ã®å€¤ã‚’è¦‹ã¦ã¿ã‚‹
    center_u = u[Hb//2, Wb//2].item()
    center_v = v[Hb//2, Wb//2].item()
    center_z = depth[Hb//2, Wb//2].item()
    print(f"Grid Center -> Cam Depth: {center_z:.2f}m, UV: ({center_u:.1f}, {center_v:.1f})")

    # 4. Grid Sampleç”¨æ­£è¦åŒ– (-1 ~ 1)
    grid_x = 2.0 * (u / (IMG_W - 1.0)) - 1.0
    grid_y = 2.0 * (v / (IMG_H - 1.0)) - 1.0
    
    # ãƒã‚¹ã‚¯é©ç”¨ï¼ˆç”»è§’å¤–ã‚’é£›ã°ã™ï¼‰
    # grid_sampleã¯ç¯„å›²å¤–(-1~1ã®å¤–)ã‚’å‚ç…§ã™ã‚‹ã¨padding_modeã«å¾“ã†
    # ã“ã“ã§ã¯æ˜ç¤ºçš„ã«ç¯„å›²å¤–ã®å€¤ã‚’è¨­å®šã™ã‚‹å¿…è¦ã¯ãªã„ãŒã€Z<0ç­‰ã¯ã‚±ã‚¢ãŒå¿…è¦
    # ZãŒè² ï¼ˆã‚«ãƒ¡ãƒ©è£ï¼‰ã®å ´æ‰€ã¯ grid_x, grid_y ã‚’ -2 (ç¯„å›²å¤–) ã«é£›ã°ã™
    invalid = ~valid_mask
    grid_x[invalid] = -2.0
    grid_y[invalid] = -2.0
    
    grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0) # (1, H, W, 2)
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    bev = F.grid_sample(img_t, grid, mode="bilinear", padding_mode="zeros", align_corners=True)

    print("points_base x(min,max) =", points_base[...,0].min().item(), points_base[...,0].max().item())
    print("points_base y(min,max) =", points_base[...,1].min().item(), points_base[...,1].max().item())

    return bev

# ---- ãƒ¡ã‚¤ãƒ³å‡¦ç† ----
with h5py.File(PATH, "r") as f:
    rgb = f["rgb"]
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’1æšãƒ­ãƒ¼ãƒ‰
    i = 0
    img_np = rgb[i] # (64, 64, 3)
    img_t = torch.from_numpy(img_np).float() / 255.0
    img_t = img_t.permute(2, 0, 1).unsqueeze(0) # (1, 3, 64, 64)
    
    # å®Ÿè¡Œ
    bev_out = generate_bev(img_t, BEV_H, BEV_W)
    
    # è¡¨ç¤º
    bev_np = bev_out[0].permute(1, 2, 0).clamp(0, 1).numpy()
    
    plt.figure(figsize=(10, 5))
    
    # å…ƒç”»åƒ
    plt.subplot(1, 2, 1)
    plt.title(f"Front Camera\n(Size: {IMG_W}x{IMG_H})")
    plt.imshow(img_np)
    # ä¸­å¿ƒç‚¹ç›®å®‰
    plt.plot(cx, cy, 'r+', label="Center")
    plt.axis("off")
    
    # BEV
    plt.subplot(1, 2, 2)
    plt.title(f"BEV (Top View)\nUp=+X(Forward), Left=+Y")
    plt.imshow(bev_np, extent=[Y_WIDTH/2, -Y_WIDTH/2, X_MIN, X_MAX])
    plt.xlabel("Y (Left+, Right-)")
    plt.ylabel("X (Forward)")
    # ãƒ­ãƒœãƒƒãƒˆä½ç½®ã®æ–¹å‘ã‚’ç¤ºã™çŸ¢å°
    # plt.arrow(0, X_MIN, 0, 0.2, head_width=0.1, head_length=0.1, fc='red', ec='red')
    # plt.text(0, X_MIN-0.1, "Robot", ha='center', color='red')

   

    
    plt.show()





    import h5py
import torch
import matplotlib.pyplot as plt

# PATH, generate_bev, BEV_H, BEV_W, IMG_W, IMG_H, cx, cy, X_MIN, X_MAX, Y_WIDTH ã¯
# ã‚ãªãŸã®æ—¢å­˜å®šç¾©ã‚’ãã®ã¾ã¾ä½¿ã†å‰æ

STRIDE = 10
N_SHOW = 5
IDX0 = 0

# with h5py.File(PATH, "r") as f:
#     rgb = f["rgb"]  # (N,64,64,3) uint8
#     N = rgb.shape[0]

#     idxs = [IDX0 + k * STRIDE for k in range(N_SHOW)]
#     idxs = [i for i in idxs if i < N]
#     n = len(idxs)

#     plt.figure(figsize=(10, 3 * n))

#     for row, i in enumerate(idxs):
#         img_np = rgb[i]  # (64,64,3) uint8

#         # (1,3,64,64) float
#         img_t = torch.from_numpy(img_np).float() / 255.0
#         img_t = img_t.permute(2, 0, 1).unsqueeze(0)

#         # BEV (1,3,BEV_H,BEV_W)
#         bev_out = generate_bev(img_t, BEV_H, BEV_W)

#         # (BEV_H,BEV_W,3)
#         bev_np = bev_out[0].permute(1, 2, 0).clamp(0, 1).cpu().numpy()

#         # --- RGB ---
#         ax1 = plt.subplot(n, 2, row * 2 + 1)
#         ax1.set_title(f"RGB idx={i}")
#         ax1.imshow(img_np)
#         ax1.plot(cx, cy, "r+")
#         ax1.axis("off")

#         # --- BEV ---
#         ax2 = plt.subplot(n, 2, row * 2 + 2)
#         ax2.set_title(f"BEV idx={i}  (Up=+X, Left=+Y)")
#         ax2.imshow(bev_np, extent=[Y_WIDTH/2, -Y_WIDTH/2, X_MIN, X_MAX])
#         ax2.set_xlabel("Y (Left+, Right-)")
#         ax2.set_ylabel("X (Forward)")

#     plt.tight_layout()
#     plt.show()


import h5py, numpy as np
from scipy.spatial.transform import Rotation as R

# PATH="teacher_static.h5"
with h5py.File(PATH,"r") as f:
    q = f["root_state_w"][:,3:7]  # (N,4) wxyz ã®ã¯ãš
    # scipy ã¯ xyzw ãªã®ã§ä¸¦ã¹æ›¿ãˆ
    q_xyzw = np.stack([q[:,1],q[:,2],q[:,3],q[:,0]], axis=1)
    eul = R.from_quat(q_xyzw).as_euler("xyz", degrees=True)  # roll,pitch,yaw
    roll = eul[:,0]; pitch = eul[:,1]; yaw = eul[:,2]
    print("roll deg mean/std/min/max:", roll.mean(), roll.std(), roll.min(), roll.max())
    print("pitch deg mean/std/min/max:", pitch.mean(), pitch.std(), pitch.min(), pitch.max())


import h5py, numpy as np
from scipy.spatial.transform import Rotation as R

with h5py.File(PATH,"r") as f:
    q = f["root_state_w"][:,3:7]  # wxyz
    q_xyzw = np.stack([q[:,1],q[:,2],q[:,3],q[:,0]], axis=1)
    eul = R.from_quat(q_xyzw).as_euler("xyz", degrees=True)
    roll, pitch, yaw = eul[:,0], eul[:,1], eul[:,2]
    print("corr(roll,yaw)=", np.corrcoef(roll, yaw)[0,1])


import numpy as np
from scipy.spatial.transform import Rotation as R

# q_bc_wxyz = np.array([0.4056, -0.5792, 0.4056, -0.5792])
q_bc_xyzw = np.array([q_bc_wxyz[1], q_bc_wxyz[2], q_bc_wxyz[3], q_bc_wxyz[0]])
eul = R.from_quat(q_bc_xyzw).as_euler("xyz", degrees=True)
print("camera offset euler xyz [deg] roll,pitch,yaw =", eul)






with h5py.File(PATH, "r") as f:
    print("Keys in attrs:", list(f.attrs.keys()))
    
    # 1. è§£åƒåº¦ (res)
    if "ray_resolution" in f.attrs:
        res_true = f.attrs["ray_resolution"]
        print(f"âœ… True Resolution (res): {res_true}")
    else:
        print("âš ï¸ 'ray_resolution' not found in attrs")

    # 2. ç‰©ç†ã‚µã‚¤ã‚º (L, W)
    if "ray_size_xy" in f.attrs:
        size_true = f.attrs["ray_size_xy"]
        L_true, W_true = size_true[0], size_true[1]
        print(f"âœ… True Size (L, W): {L_true}, {W_true}")
        
        # ã‚°ãƒªãƒƒãƒ‰æ•°æ¤œç®—
        Hb = int(round(L_true / res_true)) + 1
        Wb = int(round(W_true / res_true)) + 1
        print(f"   -> Expected Grid Shape (Hb, Wb): ({Hb}, {Wb})")
    else:
        print("âš ï¸ 'ray_size_xy' not found in attrs")

    # 3. è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã®è¨­å®šã¨æ¯”è¼ƒ
    print("-" * 20)
    print("ã‚ãªãŸã®è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã®è¨­å®š: res=0.02, L=1.2, W=0.6")
    
    if "ray_size_xy" in f.attrs:
        if not np.isclose(L_true, 1.2) or not np.isclose(W_true, 0.6):
            print("ğŸš¨ã€è­¦å‘Šã€‘L, W ã®å€¤ãŒã‚ºãƒ¬ã¦ã„ã¾ã™ï¼è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ï¼")
        else:
            print("values match. (å€¤ã¯åˆã£ã¦ã„ã¾ã™)")